{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de7c94a4",
   "metadata": {},
   "source": [
    "1. Pick one of the datasets from the ChatBot session(s) of the TUT demo (or from your own ChatBot session if you wish) and use the code produced through the ChatBot interactions to import the data and confirm that the dataset has missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e391b307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_n           0\n",
       "id              1\n",
       "name            0\n",
       "gender          0\n",
       "species         0\n",
       "birthday        0\n",
       "personality     0\n",
       "song           11\n",
       "phrase          0\n",
       "full_id         0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f289198f",
   "metadata": {},
   "source": [
    "2. Start a new ChatBot session with an initial prompt introducing the dataset you're using and request help to determine how many columns and rows of data a pandas DataFrame has, and then\n",
    "\n",
    "(1)use code provided in your ChatBot session to print out the number of rows and columns of the dataset; \n",
    "\n",
    "(2)and,write your own general definitions of the meaning of \"observations\" and \"variables\" based on asking the ChatBot to explain these terms in the context of your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b125b1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(391, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd20aab",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "General definition of \"observations\" and \"variables\" by myself:\n",
    "\n",
    "Observation: Each thing in the data table is an observation\n",
    "\n",
    "Variable: The different characteristics or attributes of each thing in the data table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e093935b",
   "metadata": {},
   "source": [
    "3. Ask the ChatBot how you can provide simple summaries of the columns in the dataset and use the suggested code to provide these summaries for your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8a9e257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 391 entries, 0 to 390\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   row_n        391 non-null    int64 \n",
      " 1   id           390 non-null    object\n",
      " 2   name         391 non-null    object\n",
      " 3   gender       391 non-null    object\n",
      " 4   species      391 non-null    object\n",
      " 5   birthday     391 non-null    object\n",
      " 6   personality  391 non-null    object\n",
      " 7   song         380 non-null    object\n",
      " 8   phrase       391 non-null    object\n",
      " 9   full_id      391 non-null    object\n",
      " 10  url          391 non-null    object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 33.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gender\n",
       "male      204\n",
       "female    187\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "villagers_data = pd.read_csv(url)\n",
    "villagers_data.info()\n",
    "villagers_data.describe()\n",
    "villagers_data.describe(include='all')\n",
    "villagers_data.isnull().sum()\n",
    "villagers_data.head()\n",
    "villagers_data['species'].value_counts()\n",
    "villagers_data['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f534d2",
   "metadata": {},
   "source": [
    "4. If the dataset you're using has (a) non-numeric variables and (b) missing values in numeric variables, explain (perhaps using help from a ChatBot if needed) the discrepancies between size of the dataset given by df.shape and what is reported by df.describe() with respect to (a) the number of columns it analyzes and (b) the values it reports in the \"count\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cc76357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_n           0\n",
       "id              1\n",
       "name            0\n",
       "gender          0\n",
       "species         0\n",
       "birthday        0\n",
       "personality     0\n",
       "song           11\n",
       "phrase          0\n",
       "full_id         0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "villagers_data = pd.read_csv(url)\n",
    "villagers_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0ed4b3",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Because there are missing values ​​in this dataset,\n",
    "\n",
    "Difference between df.shape and df.describe():\n",
    "\n",
    "df.shape displays the total number of rows and columns in the dataset, regardless of missing values ​​or data types.\n",
    "\n",
    "df.describe() by default only summarizes numeric columns and does not include non-numeric columns. Therefore, the number of columns displayed in df.describe() is less than the number of columns reported in df.shape.\n",
    "\n",
    "Difference between the \"count\" column in df.describe():\n",
    "\n",
    "The \"count\" column in df.describe() only counts the number of non-missing values.\n",
    "\n",
    "Reason for the difference:\n",
    "Numeric vs. non-numeric columns: df.describe() by default only summarizes numeric columns, while df.shape includes all columns.\n",
    "\n",
    "Missing data: The \"count\" column in df.describe() only counts non-missing values ​​and therefore may be less than the total number of rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca50aa4e",
   "metadata": {},
   "source": [
    "5. Use your ChatBot session to help understand the diference between the following and then provide your ownparaphrasing summarization of that difference\n",
    "*an \"attribute\", such as df.shape which does not end with ()\n",
    "*and a \"method\", such as df.describe() which does end with ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f748e12",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Attribute: used to store data or data characteristics, do not require parentheses.\n",
    "\n",
    "Method: perform operations or calculations, require parentheses (even if no parameters are passed)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb82b2b",
   "metadata": {},
   "source": [
    "6. The df.describe() method provides the 'count', 'mean', 'std', 'min', '25%' '50%' '75%' and 'max'summary statistics for each variable it analyzes. Give the definitions (perhaps using help from the chatBot ifneeded) of each of these summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c732c15d",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Count: the number of non-missing values.\n",
    "\n",
    "Mean: the arithmetic mean of all non-missing values.\n",
    "\n",
    "Standard Deviation: a measure of the dispersion of data values. The larger the standard deviation, the more \n",
    "\n",
    "dispersed the data distribution.\n",
    "\n",
    "Minimum: the smallest value in the data set.\n",
    "\n",
    "25th Percentile/First Quartile: the location of the smallest 25% of the values in the data.\n",
    "\n",
    "50th Percentile/Median: the data point below half of the values in the data.\n",
    "\n",
    "75th Percentile/Third Quartile: the location of 75% of the values in the data.\n",
    "\n",
    "Maximum: the maximum value in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50db1bea",
   "metadata": {},
   "source": [
    "7. Missing data can be considered \"across rows\" or \"down columns\". Consider how df.dropna() or deldf i' col'] should be applied to most eficiently use the available non-missing data in your dataset and brieflyanswer the following questions in your own words\n",
    "\n",
    "(1)Provide an example of a \"use case\" in which using df.dropna() might be peferred over using del df['col']\n",
    "\n",
    "(2)Provide an exammple of \"the opposite use case\" in which using del df[' col'] might be preferred over using df. dropna()\n",
    "\n",
    "(3)Discuss why applying del df[' col'] before df.dropna() when both are used together could be important\n",
    "\n",
    "(4)Remove all missing data from one of the datasets you're considering using some combination of del df[' col'] and/ordf.dropna() and give a justification for your approach, including a \"before and after\" report of the results of your approach foryour dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f89c3c",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "(1)When to use df.dropna():\n",
    "When only a few rows in the dataset have missing values, it is better to use df.dropna() to delete these rows and keep most of the data.\n",
    "\n",
    "(2)When to use del df['col']:\n",
    "When a column has a lot of missing values ​​and is not important for analysis, it is better to delete the column directly to avoid losing other useful data.\n",
    "\n",
    "(3)Why use del df['col'] first and then df.dropna():\n",
    "Deleting the column first can avoid deleting too many rows due to missing values ​​in the column and keep more data.\n",
    "\n",
    "(4)Operation and results of deleting missing values:\n",
    "Combining del df['col'] and df.dropna() to delete missing values ​​provides data dimensions and results before and after cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58bbde0",
   "metadata": {},
   "source": [
    "8.Give brief explanations in your own words for any requested answers to the questions below\n",
    "\n",
    "1. Use your ChatBot session to understand what df.groupby(\"col1\") [\"col2\"] .describe() does and then demonstrate andexplain this using a different example from the \"titanic\" data set other than what the ChatBot automatically provide for you\n",
    "\n",
    "2. Assuming you've not yet removed missing values in the manner of question \"7\" above, df.describe() would have differentvalues in the count value for different data columns depending on the misingness present in the original data. Why do thesecapture something fundamentally diferent from the values in the count that result from doing something likedf.groupby(\"col1\")[\"col2\"].describe()?\n",
    "\n",
    "3. lintentionally introduce the following errors into your code and report your opinion as to whether it's easier to (a) work in a ChatBotsession to fix the erors, or (b) use google to search for and fix errors: first share the errors you get in the ChatBot session and seeif you can work with ChatBot to troubleshoot and fix the coding errors, and then see if you think a google search for the errorprovides the necessary toubleshooting help more quickly than ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3d4b46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
      "       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n",
      "       'alive', 'alone'],\n",
      "      dtype='object')\n",
      "        count       mean        std   min   25%   50%   75%   max\n",
      "pclass                                                           \n",
      "1       186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0\n",
      "2       173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0\n",
      "3       355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "print(df.head())\n",
    "print(df.columns)\n",
    "age_stats_by_class = df.groupby(\"pclass\")[\"age\"].describe()\n",
    "print(age_stats_by_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f925e329",
   "metadata": {},
   "source": [
    "Explaination:\n",
    "\n",
    "`df.groupby(\"Pclass\")[\"Age\"].describe()` is used to group the passengers in the Titanic dataset by class (`Pclass`) and count the age of the passengers in each class group (`Age`). This command generates information such as the count, mean, and standard deviation of the age of the passengers in each class group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9099c14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n",
      "        count       mean        std   min   25%   50%   75%   max\n",
      "pclass                                                           \n",
      "1       186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0\n",
      "2       173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0\n",
      "3       355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "print(df.describe())\n",
    "age_stats_by_class = df.groupby(\"pclass\")[\"age\"].describe()\n",
    "print(age_stats_by_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fda3493",
   "metadata": {},
   "source": [
    "Explaination:\n",
    "\n",
    "The `count` in `df.describe()` represents the number of non-missing values ​​in the entire column, while the `count` in `df.groupby(\"Pclass\")[\"Age\"].describe()` is based on the number of non-missing values ​​in each `Pclass` group. Therefore, the `count` values ​​for each group may be different because they reflect how many passengers in each group provided age data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8671b3",
   "metadata": {},
   "source": [
    "Chatgpt solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfa5f507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived      pclass         age       sibsp       parch        fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4fb6fe",
   "metadata": {},
   "source": [
    "Google solution:\n",
    "\n",
    "To resolve the NameError: name 'pd' is not defined , you need to import Pandas before using it. The standard convention is to import pandas at the beginning of your script and alias it as pd for easier use. This code will run without raising a NameError because pandas is imported before it's used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e68e12",
   "metadata": {},
   "source": [
    "Comparition:\n",
    "\n",
    "ChatBot quickly identified the problem and provided a simple, intuitive solution. It not only explained why the error occurred, but also showed how to properly import the Pandas library in the code, providing a clear example.\n",
    "\n",
    "The Google search result accurately explains the problem and provides a solution, noting that Pandas needs to be imported before using it. However, it does not provide a complete code example like the ChatBot does.\n",
    "\n",
    "In terms of efficiency and details in problem solving, ChatBot’s response is more comprehensive. It not only explains the cause of the error, but also provides detailed correction code examples to help users quickly solve the problem. Google Search also provides explanations and solutions to the problem, but relatively speaking, ChatBot’s feedback is more specific and practical, especially providing complete code examples, which solves the problem more directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fe3fe3",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8b4157",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70b1220d",
   "metadata": {},
   "source": [
    "ChatGpt told me I can't share the link, and when I do it gives me an error and the screen goes all white and tells me an error has occurred, so I pasted the summary in a Google Doc.\n",
    "link:https://docs.google.com/document/d/1jOzCXjy1DaHg3kylSJimK_AzGnbgggH3uNdcijPs3yc/edit?pli=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb336760",
   "metadata": {},
   "source": [
    "Summary of Chatbot:\n",
    "Dataset Overview:\n",
    "\n",
    "1.You wanted to understand the size of your dataset, and I explained how to check for the number of rows and columns using the .shape attribute in pandas.\n",
    "I clarified the difference between observations (rows) and variables (columns) in a dataset.\n",
    "Missing Values:\n",
    "\n",
    "2.We discussed methods to check for missing values using .isnull().sum() to count missing values column-wise, and .isnull().values.any() to check if any missing values exist in the dataset.\n",
    "Discrepancies Between Dataset Size and Summary Statistics:\n",
    "\n",
    "3.I explained the potential discrepancy between the dataset size given by .shape and the output of .describe(), such as missing values reducing the \"count\" for columns, and how .describe() only includes numerical columns by default.\n",
    "Attributes vs Methods:\n",
    "\n",
    "4.I explained the difference between attributes (like df.shape, which store data) and methods (like df.describe(), which perform actions).\n",
    "Summary Statistics Definitions:\n",
    "\n",
    "5.I provided definitions for each of the summary statistics returned by .describe():\n",
    "Count: Number of non-missing values.\n",
    "Mean: Arithmetic average.\n",
    "Std: Standard deviation (variation in the data).\n",
    "Min: Minimum value.\n",
    "25%: 25th percentile (first quartile).\n",
    "50%: 50th percentile (median).\n",
    "75%: 75th percentile (third quartile).\n",
    "Max: Maximum value.\n",
    "\n",
    "6.Reading CSV with encoding issue: I encountered a UnicodeDecodeError when trying to read a CSV file from a URL due to encoding issues. The suggested solution was to use a different encoding like ISO-8859-1 when reading the file using pandas.read_csv(), which solved the issue.\n",
    "\n",
    "7.Explanation of ab.isna().sum(axis=0): I asked about this line of code, and it was explained that ab.isna() checks for missing values (NaNs) in the DataFrame ab, and sum(axis=0) counts the number of NaNs in each column.\n",
    "\n",
    "8.Error during type casting: When I tried to cast columns like NumPages and Pub year to integers, I encountered an IntCastingNaNError because the columns contained missing values. Solutions provided included:\n",
    "\n",
    "9.Dropping rows with missing values using dropna().\n",
    "Filling missing values with a specific value using fillna(), followed by the data type conversion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
